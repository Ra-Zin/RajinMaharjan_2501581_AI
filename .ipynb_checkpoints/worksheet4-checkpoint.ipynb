{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d933d0b-f882-43a1-9f81-8a737c6d3071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "52f6810d-3220-4f79-9a7c-78db14e35a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:\n",
      "    Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1   \n",
      "\n",
      "The shape of dataset is: (768, 9)\n",
      "\n",
      "The null values are:\n",
      "Pregnancies                 0\n",
      "Glucose                     0\n",
      "BloodPressure               0\n",
      "SkinThickness               0\n",
      "Insulin                     0\n",
      "BMI                         0\n",
      "DiabetesPedigreeFunction    0\n",
      "Age                         0\n",
      "Outcome                     0\n",
      "dtype: int64\n",
      "\n",
      "Summary Statistics:\n",
      "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
      "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
      "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
      "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
      "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
      "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
      "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
      "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
      "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
      "\n",
      "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
      "count  768.000000                768.000000  768.000000  768.000000  \n",
      "mean    31.992578                  0.471876   33.240885    0.348958  \n",
      "std      7.884160                  0.331329   11.760232    0.476951  \n",
      "min      0.000000                  0.078000   21.000000    0.000000  \n",
      "25%     27.300000                  0.243750   24.000000    0.000000  \n",
      "50%     32.000000                  0.372500   29.000000    0.000000  \n",
      "75%     36.600000                  0.626250   41.000000    1.000000  \n",
      "max     67.100000                  2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "#Problem 1\n",
    "#1 Load the data\n",
    "\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "    \n",
    "print(f\"Dataset:\\n {df.head()} \\n\") #shows few rows in dataset\n",
    "\n",
    "print(f\"The shape of dataset is: {df.shape}\\n\") #gets the shape of the dataset(rows, columns)\n",
    "\n",
    "print(f\"The null values are:\\n{df.isnull().sum()}\\n\") #checks the null values\n",
    "\n",
    "print(\"Summary Statistics:\")\n",
    "print(df.describe()) #gets summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ea781f83-cf4c-46e7-aaad-b19d421cedb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 Handle missing data\n",
    "missing_data = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n",
    "df[missing_data] = df[missing_data].replace(0, np.nan)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9c630380-3938-4255-95e4-a203830cafca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (537, 8)\n",
      "Testing set size: (231, 8)\n"
     ]
    }
   ],
   "source": [
    "#3 Feature Engineering\n",
    "x = df.drop(\"Outcome\", axis = 1)\n",
    "y = df[\"Outcome\"]\n",
    "\n",
    "np.random.seed(42)\n",
    "shuffled_indices = np.random.permutation(len(df))\n",
    "\n",
    "train_size = int(0.7 * len(df))\n",
    "\n",
    "train_indices = shuffled_indices[:train_size]\n",
    "test_indices  = shuffled_indices[train_size:]\n",
    "\n",
    "x_train = x.iloc[train_indices]\n",
    "x_test  = x.iloc[test_indices]\n",
    "\n",
    "y_train = y.iloc[train_indices]\n",
    "y_test  = y.iloc[test_indices]\n",
    "\n",
    "print(\"Training set size:\", x_train.shape)\n",
    "print(\"Testing set size:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a6c5e87f-7dda-4acd-9d7f-58db9ff7a143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0 1]\n"
     ]
    }
   ],
   "source": [
    "#4 Implement KNN\n",
    "\n",
    "# Ultra-simple KNN for quick understanding\n",
    "import numpy as np\n",
    "\n",
    "# Simple KNN in one function\n",
    "def simple_knn(x_train, y_train, x_test, k=3):\n",
    "    \"\"\"Simplest possible KNN implementation\"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for test_point in X_test:\n",
    "        # Calculate distances to all training points\n",
    "        distances = []\n",
    "        for i, train_point in enumerate(X_train):\n",
    "            # Euclidean distance\n",
    "            dist = np.sqrt(np.sum((test_point - train_point) ** 2))\n",
    "            distances.append((dist, y_train[i]))\n",
    "        \n",
    "        # Sort and get k nearest\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "        nearest = distances[:k]\n",
    "        \n",
    "        # Majority vote\n",
    "        votes = {}\n",
    "        for dist, label in nearest:\n",
    "            votes[label] = votes.get(label, 0) + 1\n",
    "        \n",
    "        # Predict most common label\n",
    "        predicted = max(votes, key=votes.get)\n",
    "        predictions.append(predicted)\n",
    "    \n",
    "    return np.array(predictions)\n",
    "\n",
    "# Simple scaling\n",
    "def simple_scale(x_train, x_test):\n",
    "    \"\"\"Simple standardization\"\"\"\n",
    "    mean = x_train.mean(axis=0)\n",
    "    std = x_train.std(axis=0)\n",
    "    std[std == 0] = 1  # Avoid division by zero\n",
    "    \n",
    "    X_train_scaled = (X_train - mean) / std\n",
    "    X_test_scaled = (X_test - mean) / std\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "# Quick test\n",
    "if __name__ == \"__main__\":\n",
    "    # Quick test data\n",
    "    X_train = np.array([[1,1], [2,2], [3,3], [8,8], [9,9]])\n",
    "    y_train = np.array([0, 0, 0, 1, 1])\n",
    "    X_test = np.array([[1.5, 1.5], [8.5, 8.5]])\n",
    "    \n",
    "    # Predict\n",
    "    preds = simple_knn(X_train, y_train, X_test, k=2)\n",
    "    print(f\"Predictions: {preds}\")  # Should be [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "35d2f0d7-fb49-498a-bfeb-f1e2cf61c13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Statistics (Original):\n",
      "X_train shape: (69, 2)\n",
      "X_test shape: (30, 2)\n",
      "\n",
      "Feature ranges in training data:\n",
      "Feature 1: Min=3.28, Max=16.87\n",
      "Feature 2: Min=804.03, Max=3272.02\n",
      "\n",
      "Feature standard deviations:\n",
      "Feature 1: Std=4.15\n",
      "Feature 2: Std=836.34\n",
      "\n",
      "1. ORIGINAL DATA (No Scaling):\n",
      "k=1: Accuracy = 100.00%\n",
      "k=3: Accuracy = 100.00%\n",
      "k=5: Accuracy = 100.00%\n",
      "\n",
      "2. STANDARDIZED DATA (Z-score):\n",
      "k=1: Accuracy = 100.00%\n",
      "k=3: Accuracy = 100.00%\n",
      "k=5: Accuracy = 100.00%\n",
      "\n",
      "3. NORMALIZED DATA (Min-Max):\n",
      "k=1: Accuracy = 100.00%\n",
      "k=3: Accuracy = 100.00%\n",
      "k=5: Accuracy = 100.00%\n"
     ]
    }
   ],
   "source": [
    "#Problem 2\n",
    "#1 repeat the classification task\n",
    "\n",
    "def standardize(X_train, X_test):\n",
    "    \"\"\"Standardization (Z-score normalization)\"\"\"\n",
    "    mean = np.mean(X_train, axis=0)\n",
    "    std = np.std(X_train, axis=0)\n",
    "    std = np.where(std == 0, 1e-8, std)  # Avoid division by zero\n",
    "    \n",
    "    X_train_scaled = (X_train - mean) / std\n",
    "    X_test_scaled = (X_test - mean) / std\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "def normalize(X_train, X_test):\n",
    "    \"\"\"Min-Max Normalization\"\"\"\n",
    "    min_val = np.min(X_train, axis=0)\n",
    "    max_val = np.max(X_train, axis=0)\n",
    "    range_val = max_val - min_val\n",
    "    range_val = np.where(range_val == 0, 1.0, range_val)  # Avoid division by zero\n",
    "    \n",
    "    X_train_scaled = (X_train - min_val) / range_val\n",
    "    X_test_scaled = (X_test - min_val) / range_val\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "# Function to compare KNN performance with and without scaling\n",
    "def compare_scaling_effects(X_train, y_train, X_test, y_test):\n",
    "    results = {}\n",
    "    k_values = [1, 3, 5]\n",
    "    \n",
    "    # Test 1: Original data (no scaling)\n",
    "    print(\"\\n1. ORIGINAL DATA (No Scaling):\")\n",
    "    print(\"-\" * 30)\n",
    "    for k in k_values:\n",
    "        predictions = knn_predict(X_train, y_train, X_test, k)\n",
    "        accuracy = calculate_accuracy(y_test, predictions)\n",
    "        results[f'original_k{k}'] = accuracy\n",
    "        print(f\"k={k}: Accuracy = {accuracy:.2%}\")\n",
    "    \n",
    "    # Test 2: Standardized data\n",
    "    print(\"\\n2. STANDARDIZED DATA (Z-score):\")\n",
    "    X_train_std, X_test_std = standardize(X_train, X_test)\n",
    "    for k in k_values:\n",
    "        predictions = knn_predict(X_train_std, y_train, X_test_std, k)\n",
    "        accuracy = calculate_accuracy(y_test, predictions)\n",
    "        results[f'standardized_k{k}'] = accuracy\n",
    "        print(f\"k={k}: Accuracy = {accuracy:.2%}\")\n",
    "    \n",
    "    # Test 3: Normalized data\n",
    "    print(\"\\n3. NORMALIZED DATA (Min-Max):\")\n",
    "    print(\"-\" * 30)\n",
    "    X_train_norm, X_test_norm = normalize(X_train, X_test)\n",
    "    for k in k_values:\n",
    "        predictions = knn_predict(X_train_norm, y_train, X_test_norm, k)\n",
    "        accuracy = calculate_accuracy(y_test, predictions)\n",
    "        results[f'normalized_k{k}'] = accuracy\n",
    "        print(f\"k={k}: Accuracy = {accuracy:.2%}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Create a more realistic dataset to demonstrate scaling effects\n",
    "def create_realistic_data():\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create 3 classes\n",
    "    n_samples = 100\n",
    "    \n",
    "    # Class 0: Feature 1 has small values, Feature 2 has large values\n",
    "    class0_feat1 = np.random.normal(5, 1, n_samples//3)\n",
    "    class0_feat2 = np.random.normal(1000, 100, n_samples//3)\n",
    "    class0 = np.column_stack([class0_feat1, class0_feat2])\n",
    "    \n",
    "    # Class 1\n",
    "    class1_feat1 = np.random.normal(10, 1, n_samples//3)\n",
    "    class1_feat2 = np.random.normal(2000, 100, n_samples//3)\n",
    "    class1 = np.column_stack([class1_feat1, class1_feat2])\n",
    "    \n",
    "    # Class 2\n",
    "    class2_feat1 = np.random.normal(15, 1, n_samples//3)\n",
    "    class2_feat2 = np.random.normal(3000, 100, n_samples//3)\n",
    "    class2 = np.column_stack([class2_feat1, class2_feat2])\n",
    "    \n",
    "    # Combine\n",
    "    X = np.vstack([class0, class1, class2])\n",
    "    y = np.array([0]*(n_samples//3) + [1]*(n_samples//3) + [2]*(n_samples//3))\n",
    "    \n",
    "    # Shuffle\n",
    "    indices = np.random.permutation(len(X))\n",
    "    X = X[indices]\n",
    "    y = y[indices]\n",
    "    \n",
    "    # Split into train and test\n",
    "    split_idx = int(0.7 * len(X))\n",
    "    X_train = X[:split_idx]\n",
    "    y_train = y[:split_idx]\n",
    "    X_test = X[split_idx:]\n",
    "    y_test = y[split_idx:]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Run comparison with realistic data\n",
    "def main():\n",
    "    # Use the realistic dataset\n",
    "    X_train, y_train, X_test, y_test = create_realistic_data()\n",
    "    \n",
    "    print(\"\\nDataset Statistics (Original):\")\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "    print(f\"\\nFeature ranges in training data:\")\n",
    "    print(f\"Feature 1: Min={X_train[:,0].min():.2f}, Max={X_train[:,0].max():.2f}\")\n",
    "    print(f\"Feature 2: Min={X_train[:,1].min():.2f}, Max={X_train[:,1].max():.2f}\")\n",
    "    print(f\"\\nFeature standard deviations:\")\n",
    "    print(f\"Feature 1: Std={X_train[:,0].std():.2f}\")\n",
    "    print(f\"Feature 2: Std={X_train[:,1].std():.2f}\")\n",
    "    \n",
    "    # Run comparison\n",
    "    results = compare_scaling_effects(X_train, y_train, X_test, y_test)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e59fe56-9b17-4a60-82d9-c61b1a4bdc47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
